{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters babyyy, change accordingly\n",
    "Channel_uses = 4\n",
    "Epochs = 10000\n",
    "Noise_variance = 1e-4\n",
    "Pert_variance = 1e-4\n",
    "Batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tx_loss(y_true, y_pred): \n",
    "    # For numerical stability, we skipped the log and exp in the cost\n",
    "    # function and  policy function. \n",
    "    return -y_true*y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbation(d):\n",
    "    W = tf.keras.backend.random_normal(shape = (2*Channel_uses,),\n",
    "    mean=0.0,stddev=Pert_variance**0.5,dtype=None,seed=None)\n",
    "    d = ((1-Pert_variance)**0.5)*d + W\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalise_ret(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    normalised = (data-mean)/(std)\n",
    "    return mean, std, normalised\n",
    "\n",
    "def denormalise(data, mean, std):\n",
    "    data = (std*data) + mean\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blah(y):\n",
    "    w = y[:,y.shape[-1]//2:] - y[:,:y.shape[-1]//2]\n",
    "    print('hehehe', w.shape)\n",
    "    t = -keras.backend.sum(w*w)/Pert_variance**2 + np.log((np.pi*Pert_variance**2)**Channel_uses)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hehehe (?, 8)\n",
      "(?, 16)\n"
     ]
    }
   ],
   "source": [
    "# tx layers\n",
    "tx_input = keras.layers.Input((1,), name='tx_input')\n",
    "# x = keras.layers.BatchNormalization()(tx_input)\n",
    "# Removing the batch normalisation layer and substituting it with a global function to maintain \n",
    "# uniformity while shrinking and inflating.\n",
    "x = tx_input\n",
    "x = keras.layers.Dense(units=10*Channel_uses, activation='elu', name='tx_10')(x)\n",
    "x = keras.layers.Dense(units=2*Channel_uses, activation='elu', name='tx_out')(x)\n",
    "xp = keras.layers.Lambda(perturbation, name='Xp')(x)\n",
    "concat = keras.layers.concatenate([x,xp], axis=1)\n",
    "policy = keras.layers.Lambda(blah)(concat)\n",
    "print(concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_model = keras.models.Model(inputs=tx_input, outputs=concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "tx_input (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tx_10 (Dense)                   (None, 40)           80          tx_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tx_out (Dense)                  (None, 8)            328         tx_10[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Xp (Lambda)                     (None, 8)            0           tx_out[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16)           0           tx_out[0][0]                     \n",
      "                                                                 Xp[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 408\n",
      "Trainable params: 408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tx_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_model = keras.models.Model(inputs=tx_input, outputs=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3ab27dd9a6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtx_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mloss_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_weights_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m           \u001b[0moutput_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    450\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m       \u001b[0mweight_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m       \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m       \u001b[0mscore_array\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m       score_array /= K.mean(\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "pert_model.compile(loss=tx_loss, optimizer='sgd')\n",
    "pert_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_input = keras.layers.Input((2*Channel_uses,), name='rx_input')\n",
    "# channel layer\n",
    "y = keras.layers.Lambda(lambda x: x+keras.backend.random_normal(\n",
    "        shape = (2*Channel_uses,), mean=0.0, stddev=Noise_variance**0.5), name='channel')(rx_input)\n",
    "\n",
    "y = keras.layers.Dense(2*Channel_uses, activation='relu', name='rx_2')(y)\n",
    "y = keras.layers.Dense(10*Channel_uses, activation='relu', name='rx_10')(y)\n",
    "pred = keras.layers.Dense(1, activation='relu', name='rx_output')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_model = keras.models.Model(inputs=rx_input, outputs=pred)\n",
    "rx_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx_model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data generator for consistency sake\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.random_uniform([0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numbers = np.random.uniform(0,1,(Batch_size,))\n",
    "y = tx_model.predict(data_numbers)\n",
    "print(y.shape)\n",
    "XP = y[:,y.shape[-1]//2:]\n",
    "estimated_vector = np.squeeze(rx_model.predict(XP))\n",
    "print(estimated_vector.shape, data_numbers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = (estimated_vector-data_numbers)**2\n",
    "l_hat = rx_model.predict(tx_model.predict(data_numbers)[:,2*Channel_uses:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_model.fit(data_numbers, l_hat, batch_size=Batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(Epochs):\n",
    "    data_numbers = np.random.uniform(0,1,(Batch_size,))\n",
    "    y = tx_model.predict(data_numbers)\n",
    "    XP = y[:,y.shape[-1]//2:]\n",
    "    estimated_vector= np.squeeze(rx_model.predict(XP))\n",
    "    l = (estimated_vector-data_numbers)**2\n",
    "    l_hat = rx_model.predict(tx_model.predict(data_numbers)[:,2*Channel_uses:])\n",
    "    pert_model.fit(data_numbers, l_hat, batch_size=Batch_size, epochs=1, verbose=0)\n",
    "    rx_model.fit(XP, data_numbers, batch_size=Batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numbers = np.random.uniform(0,1,(10,))\n",
    "y = tx_model.predict(data_numbers)\n",
    "XP = y[:,y.shape[-1]//2:]\n",
    "estimated_vector= np.squeeze(rx_model.predict(XP))\n",
    "print(data_numbers)\n",
    "print(estimated_vector)\n",
    "# l = (estimated_vector-data_numbers)**2\n",
    "# l_hat = rx_model.predict(tx_model.predict(data_numbers)[:,2*Channel_uses:])\n",
    "# pert_model.fit(data_numbers, l_hat, batch_size=Batch_size, epochs=1)\n",
    "# print(\"Tx-done\")\n",
    "# rx_model.fit(XP, data_numbers, batch_size=Batch_size, epochs=1)\n",
    "# print(\"Rx-done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
